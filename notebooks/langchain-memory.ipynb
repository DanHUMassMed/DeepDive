{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"deepseek-r1:32b\", model_provider=\"ollama\")\n",
    "model = init_chat_model(\"llama3.3\", model_provider=\"ollama\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi! I'm Bob\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke([HumanMessage(content=\"What's my name?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hi! I'm Bob.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What's my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = init_chat_model(\"deepseek-r1:32b\", model_provider=\"ollama\")\n",
    "model = init_chat_model(\"llama3.3\", model_provider=\"ollama\")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Async function for node:\n",
    "async def call_model(state: MessagesState):\n",
    "    response = await model.ainvoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define graph as before:\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "aapp = workflow.compile(checkpointer=MemorySaver())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Bob! It's nice to meet you. Is there something I can help you with or would you like to chat?\n"
     ]
    }
   ],
   "source": [
    "query = \"Hi! I'm Bob.\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "# Async invocation:\n",
    "output = await aapp.ainvoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob! You told me that when we started talking.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"What's my name?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "# Async invocation:\n",
    "output = await aapp.ainvoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a System Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You talk like a pirate. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Arrrr, greetings to ye, Bob me hearty! 'Tis a grand day to be havin' a chat, don't ye think? What be bringin' ye to these fair waters? Are ye lookin' fer treasure, or just passin' the time with a swashbucklin' pirate like meself?\n"
     ]
    }
   ],
   "source": [
    "query = \"Hi! I'm Bob.\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "# Async invocation:\n",
    "output = await app.ainvoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"deepseek-r1:32b\", model_provider=\"ollama\")\n",
    "model = init_chat_model(\"llama3.3\", model_provider=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langgraph.graph.state.CompiledStateGraph'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, AIMessage, HumanMessage, trim_messages\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=6_500_000,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "    prompt = prompt_template.invoke({\"messages\": trimmed_messages})\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "import aiosqlite\n",
    "\n",
    "\n",
    "db_path = 'checkpoints.db'\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "\n",
    "#memory = SqliteSaver(conn)\n",
    "# Does not work\n",
    "#memory = AsyncSqliteSaver(conn)\n",
    "\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "        \n",
    "print(type(app))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dan/miniforge3/envs/deep-dive/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'input': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={})]}},\n",
      " 'event': 'on_chain_start',\n",
      " 'metadata': {'thread_id': 'abc12'},\n",
      " 'name': 'LangGraph',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '5df10a42-1d4a-4db7-b2c8-338fb650fda9',\n",
      " 'tags': []}\n",
      "{'data': {'input': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={})]}},\n",
      " 'event': 'on_chain_start',\n",
      " 'metadata': {'langgraph_checkpoint_ns': '__start__:667b0be5-b56a-7127-d177-5694f2ee96b4',\n",
      "              'langgraph_node': '__start__',\n",
      "              'langgraph_path': ('__pregel_pull', '__start__'),\n",
      "              'langgraph_step': 0,\n",
      "              'langgraph_triggers': ['__start__'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': '__start__',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '3e8d95f3-b3c2-45d8-b200-8603b14d0498',\n",
      " 'tags': ['graph:step:0', 'langsmith:hidden']}\n",
      "{'data': {'input': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={})]}},\n",
      " 'event': 'on_chain_start',\n",
      " 'metadata': {'langgraph_checkpoint_ns': '__start__:667b0be5-b56a-7127-d177-5694f2ee96b4',\n",
      "              'langgraph_node': '__start__',\n",
      "              'langgraph_path': ('__pregel_pull', '__start__'),\n",
      "              'langgraph_step': 0,\n",
      "              'langgraph_triggers': ['__start__'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': '_write',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'bdb9e826-078d-48c5-b1b1-2c8ada397d64',\n",
      " 'tags': ['seq:step:1', 'langsmith:hidden', 'langsmith:hidden']}\n",
      "{'data': {'input': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={})]},\n",
      "          'output': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={})]}},\n",
      " 'event': 'on_chain_end',\n",
      " 'metadata': {'langgraph_checkpoint_ns': '__start__:667b0be5-b56a-7127-d177-5694f2ee96b4',\n",
      "              'langgraph_node': '__start__',\n",
      "              'langgraph_path': ('__pregel_pull', '__start__'),\n",
      "              'langgraph_step': 0,\n",
      "              'langgraph_triggers': ['__start__'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': '_write',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'bdb9e826-078d-48c5-b1b1-2c8ada397d64',\n",
      " 'tags': ['seq:step:1', 'langsmith:hidden', 'langsmith:hidden']}\n",
      "{'data': {'input': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={})]}},\n",
      " 'event': 'on_chain_start',\n",
      " 'metadata': {'langgraph_checkpoint_ns': '__start__:667b0be5-b56a-7127-d177-5694f2ee96b4',\n",
      "              'langgraph_node': '__start__',\n",
      "              'langgraph_path': ('__pregel_pull', '__start__'),\n",
      "              'langgraph_step': 0,\n",
      "              'langgraph_triggers': ['__start__'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': '_write',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'b7b2979b-5e3b-4093-9d60-e5412d1c7add',\n",
      " 'tags': ['seq:step:3', 'langsmith:hidden', 'langsmith:hidden']}\n",
      "{'data': {'input': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={})]},\n",
      "          'output': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={})]}},\n",
      " 'event': 'on_chain_end',\n",
      " 'metadata': {'langgraph_checkpoint_ns': '__start__:667b0be5-b56a-7127-d177-5694f2ee96b4',\n",
      "              'langgraph_node': '__start__',\n",
      "              'langgraph_path': ('__pregel_pull', '__start__'),\n",
      "              'langgraph_step': 0,\n",
      "              'langgraph_triggers': ['__start__'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': '_write',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'b7b2979b-5e3b-4093-9d60-e5412d1c7add',\n",
      " 'tags': ['seq:step:3', 'langsmith:hidden', 'langsmith:hidden']}\n",
      "{'data': {'chunk': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={})]}},\n",
      " 'event': 'on_chain_stream',\n",
      " 'metadata': {'langgraph_checkpoint_ns': '__start__:667b0be5-b56a-7127-d177-5694f2ee96b4',\n",
      "              'langgraph_node': '__start__',\n",
      "              'langgraph_path': ('__pregel_pull', '__start__'),\n",
      "              'langgraph_step': 0,\n",
      "              'langgraph_triggers': ['__start__'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': '__start__',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '3e8d95f3-b3c2-45d8-b200-8603b14d0498',\n",
      " 'tags': ['graph:step:0', 'langsmith:hidden']}\n",
      "{'data': {'input': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={})]},\n",
      "          'output': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={})]}},\n",
      " 'event': 'on_chain_end',\n",
      " 'metadata': {'langgraph_checkpoint_ns': '__start__:667b0be5-b56a-7127-d177-5694f2ee96b4',\n",
      "              'langgraph_node': '__start__',\n",
      "              'langgraph_path': ('__pregel_pull', '__start__'),\n",
      "              'langgraph_step': 0,\n",
      "              'langgraph_triggers': ['__start__'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': '__start__',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '3e8d95f3-b3c2-45d8-b200-8603b14d0498',\n",
      " 'tags': ['graph:step:0', 'langsmith:hidden']}\n",
      "{'data': {'input': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}, id='798105e7-0764-4948-bd73-7b1a1a3a6382')]}},\n",
      " 'event': 'on_chain_start',\n",
      " 'metadata': {'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'model',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '976fa5c8-7058-4be0-b4f0-40d146f03857',\n",
      " 'tags': ['graph:step:1']}\n",
      "{'data': {'input': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}, id='798105e7-0764-4948-bd73-7b1a1a3a6382')]},\n",
      " 'event': 'on_chain_start',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'trim_messages',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '41b678fc-e88d-4611-943b-46d263d4f799',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'input': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}, id='798105e7-0764-4948-bd73-7b1a1a3a6382')],\n",
      "          'output': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}, id='798105e7-0764-4948-bd73-7b1a1a3a6382')]},\n",
      " 'event': 'on_chain_end',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'trim_messages',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '41b678fc-e88d-4611-943b-46d263d4f799',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'input': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}, id='798105e7-0764-4948-bd73-7b1a1a3a6382')]}},\n",
      " 'event': 'on_prompt_start',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatPromptTemplate',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '8c4b6346-27a0-4763-9589-be474a9fea16',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'input': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}, id='798105e7-0764-4948-bd73-7b1a1a3a6382')]},\n",
      "          'output': ChatPromptValue(messages=[SystemMessage(content='Answer all questions to the best of your ability.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}, id='798105e7-0764-4948-bd73-7b1a1a3a6382')])},\n",
      " 'event': 'on_prompt_end',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatPromptTemplate',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '8c4b6346-27a0-4763-9589-be474a9fea16',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'input': {'messages': [[SystemMessage(content='Answer all questions to the best of your ability.', additional_kwargs={}, response_metadata={}),\n",
      "                                  HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}, id='798105e7-0764-4948-bd73-7b1a1a3a6382')]]}},\n",
      " 'event': 'on_chat_model_start',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'ls_model_name': 'llama3.3',\n",
      "              'ls_model_type': 'chat',\n",
      "              'ls_provider': 'ollama',\n",
      "              'ls_temperature': None,\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatOllama',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'a8b43770-f131-4493-b709-09a0d10b39e2',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2')},\n",
      " 'event': 'on_chat_model_stream',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'ls_model_name': 'llama3.3',\n",
      "              'ls_model_type': 'chat',\n",
      "              'ls_provider': 'ollama',\n",
      "              'ls_temperature': None,\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatOllama',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'a8b43770-f131-4493-b709-09a0d10b39e2',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'chunk': AIMessageChunk(content=' answer', additional_kwargs={}, response_metadata={}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2')},\n",
      " 'event': 'on_chat_model_stream',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'ls_model_name': 'llama3.3',\n",
      "              'ls_model_type': 'chat',\n",
      "              'ls_provider': 'ollama',\n",
      "              'ls_temperature': None,\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatOllama',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'a8b43770-f131-4493-b709-09a0d10b39e2',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2')},\n",
      " 'event': 'on_chat_model_stream',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'ls_model_name': 'llama3.3',\n",
      "              'ls_model_type': 'chat',\n",
      "              'ls_provider': 'ollama',\n",
      "              'ls_temperature': None,\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatOllama',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'a8b43770-f131-4493-b709-09a0d10b39e2',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2')},\n",
      " 'event': 'on_chat_model_stream',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'ls_model_name': 'llama3.3',\n",
      "              'ls_model_type': 'chat',\n",
      "              'ls_provider': 'ollama',\n",
      "              'ls_temperature': None,\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatOllama',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'a8b43770-f131-4493-b709-09a0d10b39e2',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2')},\n",
      " 'event': 'on_chat_model_stream',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'ls_model_name': 'llama3.3',\n",
      "              'ls_model_type': 'chat',\n",
      "              'ls_provider': 'ollama',\n",
      "              'ls_temperature': None,\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatOllama',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'a8b43770-f131-4493-b709-09a0d10b39e2',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'chunk': AIMessageChunk(content=' +', additional_kwargs={}, response_metadata={}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2')},\n",
      " 'event': 'on_chat_model_stream',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'ls_model_name': 'llama3.3',\n",
      "              'ls_model_type': 'chat',\n",
      "              'ls_provider': 'ollama',\n",
      "              'ls_temperature': None,\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatOllama',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'a8b43770-f131-4493-b709-09a0d10b39e2',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2')},\n",
      " 'event': 'on_chat_model_stream',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'ls_model_name': 'llama3.3',\n",
      "              'ls_model_type': 'chat',\n",
      "              'ls_provider': 'ollama',\n",
      "              'ls_temperature': None,\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatOllama',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'a8b43770-f131-4493-b709-09a0d10b39e2',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2')},\n",
      " 'event': 'on_chat_model_stream',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'ls_model_name': 'llama3.3',\n",
      "              'ls_model_type': 'chat',\n",
      "              'ls_provider': 'ollama',\n",
      "              'ls_temperature': None,\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatOllama',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'a8b43770-f131-4493-b709-09a0d10b39e2',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2')},\n",
      " 'event': 'on_chat_model_stream',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'ls_model_name': 'llama3.3',\n",
      "              'ls_model_type': 'chat',\n",
      "              'ls_provider': 'ollama',\n",
      "              'ls_temperature': None,\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatOllama',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'a8b43770-f131-4493-b709-09a0d10b39e2',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2')},\n",
      " 'event': 'on_chat_model_stream',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'ls_model_name': 'llama3.3',\n",
      "              'ls_model_type': 'chat',\n",
      "              'ls_provider': 'ollama',\n",
      "              'ls_temperature': None,\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatOllama',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'a8b43770-f131-4493-b709-09a0d10b39e2',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'chunk': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2')},\n",
      " 'event': 'on_chat_model_stream',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'ls_model_name': 'llama3.3',\n",
      "              'ls_model_type': 'chat',\n",
      "              'ls_provider': 'ollama',\n",
      "              'ls_temperature': None,\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatOllama',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'a8b43770-f131-4493-b709-09a0d10b39e2',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2')},\n",
      " 'event': 'on_chat_model_stream',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'ls_model_name': 'llama3.3',\n",
      "              'ls_model_type': 'chat',\n",
      "              'ls_provider': 'ollama',\n",
      "              'ls_temperature': None,\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatOllama',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'a8b43770-f131-4493-b709-09a0d10b39e2',\n",
      " 'tags': ['seq:step:1']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NotImplementedError in LogStreamCallbackHandler.on_llm_end callback: NotImplementedError('Trying to load an object that doesn\\'t implement serialization: {\\'lc\\': 1, \\'type\\': \\'not_implemented\\', \\'id\\': [\\'ollama\\', \\'_types\\', \\'Message\\'], \\'repr\\': \"Message(role=\\'assistant\\', content=\\'\\', images=None, tool_calls=None)\"}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model': 'llama3.3', 'created_at': '2025-02-21T13:14:27.712454Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18460429459, 'load_duration': 571318209, 'prompt_eval_count': 32, 'prompt_eval_duration': 16467000000, 'eval_count': 13, 'eval_duration': 1199000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2', usage_metadata={'input_tokens': 32, 'output_tokens': 13, 'total_tokens': 45})},\n",
      " 'event': 'on_chat_model_stream',\n",
      " 'metadata': {'checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'ls_model_name': 'llama3.3',\n",
      "              'ls_model_type': 'chat',\n",
      "              'ls_provider': 'ollama',\n",
      "              'ls_temperature': None,\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'ChatOllama',\n",
      " 'parent_ids': [],\n",
      " 'run_id': 'a8b43770-f131-4493-b709-09a0d10b39e2',\n",
      " 'tags': ['seq:step:1']}\n",
      "{'data': {'input': {'messages': [AIMessage(content='The answer to 1 + 1 is 2.', additional_kwargs={}, response_metadata={'model': 'llama3.3', 'created_at': '2025-02-21T13:14:27.712454Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18460429459, 'load_duration': 571318209, 'prompt_eval_count': 32, 'prompt_eval_duration': 16467000000, 'eval_count': 13, 'eval_duration': 1199000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2', usage_metadata={'input_tokens': 32, 'output_tokens': 13, 'total_tokens': 45})]}},\n",
      " 'event': 'on_chain_start',\n",
      " 'metadata': {'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': '_write',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '80e3e56a-3d8b-4c08-9e59-851d00802f71',\n",
      " 'tags': ['seq:step:2', 'langsmith:hidden']}\n",
      "{'data': {'input': {'messages': [AIMessage(content='The answer to 1 + 1 is 2.', additional_kwargs={}, response_metadata={'model': 'llama3.3', 'created_at': '2025-02-21T13:14:27.712454Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18460429459, 'load_duration': 571318209, 'prompt_eval_count': 32, 'prompt_eval_duration': 16467000000, 'eval_count': 13, 'eval_duration': 1199000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2', usage_metadata={'input_tokens': 32, 'output_tokens': 13, 'total_tokens': 45})]},\n",
      "          'output': {'messages': [AIMessage(content='The answer to 1 + 1 is 2.', additional_kwargs={}, response_metadata={'model': 'llama3.3', 'created_at': '2025-02-21T13:14:27.712454Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18460429459, 'load_duration': 571318209, 'prompt_eval_count': 32, 'prompt_eval_duration': 16467000000, 'eval_count': 13, 'eval_duration': 1199000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2', usage_metadata={'input_tokens': 32, 'output_tokens': 13, 'total_tokens': 45})]}},\n",
      " 'event': 'on_chain_end',\n",
      " 'metadata': {'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': '_write',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '80e3e56a-3d8b-4c08-9e59-851d00802f71',\n",
      " 'tags': ['seq:step:2', 'langsmith:hidden']}\n",
      "{'data': {'chunk': {'messages': [AIMessage(content='The answer to 1 + 1 is 2.', additional_kwargs={}, response_metadata={'model': 'llama3.3', 'created_at': '2025-02-21T13:14:27.712454Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18460429459, 'load_duration': 571318209, 'prompt_eval_count': 32, 'prompt_eval_duration': 16467000000, 'eval_count': 13, 'eval_duration': 1199000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2', usage_metadata={'input_tokens': 32, 'output_tokens': 13, 'total_tokens': 45})]}},\n",
      " 'event': 'on_chain_stream',\n",
      " 'metadata': {'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'model',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '976fa5c8-7058-4be0-b4f0-40d146f03857',\n",
      " 'tags': ['graph:step:1']}\n",
      "{'data': {'input': {'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}, id='798105e7-0764-4948-bd73-7b1a1a3a6382')]},\n",
      "          'output': {'messages': [AIMessage(content='The answer to 1 + 1 is 2.', additional_kwargs={}, response_metadata={'model': 'llama3.3', 'created_at': '2025-02-21T13:14:27.712454Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18460429459, 'load_duration': 571318209, 'prompt_eval_count': 32, 'prompt_eval_duration': 16467000000, 'eval_count': 13, 'eval_duration': 1199000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2', usage_metadata={'input_tokens': 32, 'output_tokens': 13, 'total_tokens': 45})]}},\n",
      " 'event': 'on_chain_end',\n",
      " 'metadata': {'langgraph_checkpoint_ns': 'model:457b7390-71d6-349b-120f-e1b57096a593',\n",
      "              'langgraph_node': 'model',\n",
      "              'langgraph_path': ('__pregel_pull', 'model'),\n",
      "              'langgraph_step': 1,\n",
      "              'langgraph_triggers': ['start:model'],\n",
      "              'thread_id': 'abc12'},\n",
      " 'name': 'model',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '976fa5c8-7058-4be0-b4f0-40d146f03857',\n",
      " 'tags': ['graph:step:1']}\n",
      "{'data': {'chunk': {'model': {'messages': [AIMessage(content='The answer to 1 + 1 is 2.', additional_kwargs={}, response_metadata={'model': 'llama3.3', 'created_at': '2025-02-21T13:14:27.712454Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18460429459, 'load_duration': 571318209, 'prompt_eval_count': 32, 'prompt_eval_duration': 16467000000, 'eval_count': 13, 'eval_duration': 1199000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2', usage_metadata={'input_tokens': 32, 'output_tokens': 13, 'total_tokens': 45})]}}},\n",
      " 'event': 'on_chain_stream',\n",
      " 'metadata': {'thread_id': 'abc12'},\n",
      " 'name': 'LangGraph',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '5df10a42-1d4a-4db7-b2c8-338fb650fda9',\n",
      " 'tags': []}\n",
      "{'data': {'output': {'model': {'messages': [AIMessage(content='The answer to 1 + 1 is 2.', additional_kwargs={}, response_metadata={'model': 'llama3.3', 'created_at': '2025-02-21T13:14:27.712454Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18460429459, 'load_duration': 571318209, 'prompt_eval_count': 32, 'prompt_eval_duration': 16467000000, 'eval_count': 13, 'eval_duration': 1199000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2', usage_metadata={'input_tokens': 32, 'output_tokens': 13, 'total_tokens': 45})]}}},\n",
      " 'event': 'on_chain_end',\n",
      " 'metadata': {'thread_id': 'abc12'},\n",
      " 'name': 'LangGraph',\n",
      " 'parent_ids': [],\n",
      " 'run_id': '5df10a42-1d4a-4db7-b2c8-338fb650fda9',\n",
      " 'tags': []}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc12\"}}\n",
    "inputs = {\"messages\": [HumanMessage(content=\"What is 1+1?\")]}\n",
    "\n",
    "async with AsyncSqliteSaver.from_conn_string(db_path) as saver:\n",
    "    graph = workflow.compile(checkpointer=saver)\n",
    "    async for event in graph.astream_events(inputs, config, version=\"v1\"):\n",
    "        pprint(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice to meet you, Bob! It's great to have a name to go along with our conversation. How's your day going so far, Bob?"
     ]
    }
   ],
   "source": [
    "# THIS COULD BE THE ONE I NEED\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc12\"}}\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Hi! I'm Bob.\")]}\n",
    "\n",
    "async with AsyncSqliteSaver.from_conn_string(db_path) as saver:\n",
    "    graph = workflow.compile(checkpointer=saver)        \n",
    "    async for chunk, metadata in graph.astream(\n",
    "        inputs,\n",
    "        config,\n",
    "        stream_mode=\"messages\",\n",
    "    ):\n",
    "        if isinstance(chunk, AIMessage):  # Filter to just model responses\n",
    "            print(chunk.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}, id='798105e7-0764-4948-bd73-7b1a1a3a6382'), AIMessage(content='The answer to 1 + 1 is 2.', additional_kwargs={}, response_metadata={'model': 'llama3.3', 'created_at': '2025-02-21T13:14:27.712454Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18460429459, 'load_duration': 571318209, 'prompt_eval_count': 32, 'prompt_eval_duration': 16467000000, 'eval_count': 13, 'eval_duration': 1199000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, id='run-a8b43770-f131-4493-b709-09a0d10b39e2', usage_metadata={'input_tokens': 32, 'output_tokens': 13, 'total_tokens': 45}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}, id='46cb3236-78b7-4dd8-a2c9-c17a22e91137'), AIMessage(content=\"I don't have any information about your name. Our conversation just started, and you haven't shared that with me yet! Would you like to tell me your name?\", additional_kwargs={}, response_metadata={'model': 'llama3.3', 'created_at': '2025-02-21T13:16:03.848968Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4649087875, 'load_duration': 28515833, 'prompt_eval_count': 59, 'prompt_eval_duration': 1207000000, 'eval_count': 35, 'eval_duration': 3411000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, id='run-e4ba1cff-30b9-4d51-a245-0f87dd635ebf', usage_metadata={'input_tokens': 59, 'output_tokens': 35, 'total_tokens': 94}), HumanMessage(content=\"Hi! I'm Bob.\", additional_kwargs={}, response_metadata={}, id='a27276a2-4017-4586-ad03-4f235aa72089'), AIMessage(content=\"Nice to meet you, Bob! It's great to have a name to go along with our conversation. How's your day going so far, Bob?\", additional_kwargs={}, response_metadata={'model': 'llama3.3', 'created_at': '2025-02-21T13:16:47.505399Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4403549208, 'load_duration': 32383625, 'prompt_eval_count': 109, 'prompt_eval_duration': 1234000000, 'eval_count': 32, 'eval_duration': 3135000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, id='run-7aa3217a-45a4-45b0-a166-b682f1c1e005', usage_metadata={'input_tokens': 109, 'output_tokens': 32, 'total_tokens': 141})]}\n",
      "6\n",
      "Human: What is 1+1?\n",
      "AI:    The answer to 1 + 1 is 2.\n",
      "Human: What is my name?\n",
      "AI:    I don't have any information about your name. Our conversation just started, and you haven't shared that with me yet! Would you like to tell me your name?\n",
      "Human: Hi! I'm Bob.\n",
      "AI:    Nice to meet you, Bob! It's great to have a name to go along with our conversation. How's your day going so far, Bob?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\":  \"abc12\"}}\n",
    "\n",
    "\n",
    "\n",
    "with SqliteSaver.from_conn_string(db_path) as checkpointer:\n",
    "    graph = workflow.compile(checkpointer=checkpointer)\n",
    "    state_history = graph.get_state_history(config) \n",
    "    values = next(state_history).values  \n",
    "    print(values) \n",
    "    print(len(values['messages']))\n",
    "    for message in values['messages']:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            print(f\"Human: {message.content}\")\n",
    "        else:\n",
    "            print(f\"AI:    {message.content}\")\n",
    "    \n",
    "    #state_history_list = list(state_history)\n",
    "    #print(state_history_list)\n",
    "    # for state in state_history:\n",
    "    #     print(state)\n",
    "    #     # print(f\"Step: {state.step}\")\n",
    "    #     # print(f\"Created At: {state.created_at}\")\n",
    "    #     # print(f\"Values: {state.values}\")\n",
    "    #     # print(\"-----\")\n",
    " \n",
    "    #list(graph.get_state_history(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is my name\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "async for chunk, metadata in app.astream(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if isinstance(chunk, AIMessage):  # Filter to just model responses\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "builder = StateGraph(int)\n",
    "builder.add_node(\"add_one\", lambda x: x + 1)\n",
    "builder.set_entry_point(\"add_one\")\n",
    "builder.set_finish_point(\"add_one\")\n",
    "async with AsyncSqliteSaver.from_conn_string(\"checkpoints.db\") as memory:\n",
    "    graph = builder.compile(checkpointer=memory)\n",
    "    coro = graph.ainvoke(1, {\"configurable\": {\"thread_id\": \"thread-1\"}})\n",
    "    print(asyncio.run(coro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10890af60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import AIMessage, HumanMessage, trim_messages\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "\n",
    "\n",
    "system_prompt = \"Answer all questions to the best of your ability. Answer concisely but correctly. If you do not know the answer, just say 'I don’t know.'\"\n",
    "model = init_chat_model(\"deepseek-r1:32b\", model_provider=\"ollama\")\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=6_500_000,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_prompt,\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "graph = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "    prompt = prompt_template.invoke({\"messages\": trimmed_messages})\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "graph.add_edge(START, \"model\")\n",
    "graph.add_node(\"model\", call_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN get_chat_interactions_count\n",
      "before compiled_graph\n",
      "after compiled_graph\n",
      "after state_history\n",
      "after last_interaction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"IN get_chat_interactions_count\")\n",
    "interactions_count = 0\n",
    "db_path=\"/Users/dan/Code/LLM/DeepDive/backend/resources/checkpoints.db\"\n",
    "chat_id=\"ea9123ff-9a8e-46c0-a53f-22b8f88e3202\"\n",
    "\n",
    "with SqliteSaver.from_conn_string(db_path) as checkpointer:            \n",
    "    config = {\"configurable\": {\"thread_id\": chat_id}}\n",
    "    print(\"before compiled_graph\")\n",
    "    compiled_graph = graph.compile(checkpointer=checkpointer)\n",
    "    print(\"after compiled_graph\")\n",
    "    state_history = compiled_graph.get_state_history(config) \n",
    "    print(\"after state_history\")\n",
    "    last_interaction = next(state_history, None)\n",
    "    print(\"after last_interaction\")\n",
    "    if last_interaction:\n",
    "        values = last_interaction.values  \n",
    "        if 'messages' in values:\n",
    "            interactions_count = len(values['messages'])\n",
    "            \n",
    "interactions_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dan/Code/LLM/DeepDive/backend'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/Users/dan/Code/LLM/DeepDive/backend')\n",
    "\n",
    "import app.app_session\n",
    "file_path = app.app_session.__file__\n",
    "parent_directory = os.path.dirname(file_path)\n",
    "grandparent_directory = os.path.dirname(parent_directory)\n",
    "grandparent_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-dive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
